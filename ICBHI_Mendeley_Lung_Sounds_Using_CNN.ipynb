{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g25PLQ2Ioqff"
      },
      "outputs": [],
      "source": [
        "# Enhancing Lung Sound Classification Using CNN and Mel Spectogram processing\n",
        "# Berikut langkah-langkah yang dilakukan pada penelitian lung sounds.\n",
        "# 1. Pengumpulan Dataset:\n",
        "#    Lokasi: /content/drive/MyDrive/Combination Dataset/Dataset\n",
        "#    Label dataset: Rhonchi, Crackles\n",
        "# Jumlah file di folder Rhonchi : 52   (sumber mendeley data)\n",
        "# Jumlah file di folder Crackles : 257 (sumber ICBHI)\n",
        "# Jumlah kelas: 2\n",
        "# 2. Pra-pemrosesan:\n",
        "#    a. Konversi Data Audio ke representasi tensor-float\n",
        "#    b. Frekuensi sampling dengan target sampling rate sebesar 16 kHz (untuk mencapai keseragaman dan standarisasi).\n",
        "#    c. Transformasi ke Mel Spectrogram\n",
        "# 3. Augmentasi data dari Google Brain's SpecAugment\".\n",
        "# Hasil :\n",
        "# Jumlah data untuk 1_Crackles : 514\n",
        "# Jumlah data untuk 2_Rhonchi: 514\n",
        "# 4. 10 Fold Cros Validation\n",
        "# 5. Menjalankan menggunakan CNN Model\n",
        "# evaluasi metrik seperti accuracy, precision, recall, f1_score, auc dan confusion matrix.\n",
        "#===============================================================================================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8RBeelGTVg6",
        "outputId": "32d707ff-6b9b-4d89-db15-ba6d79c2cc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.11/dist-packages (0.16.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_hub) (2.18.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "#Import library yang diperlukan\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "!pip install librosa\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "!pip install soundfile\n",
        "import librosa.display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "#import pywt\n",
        "from scipy import signal\n",
        "!pip install tensorflow tensorflow_hub librosa scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uP9gDwoTduB"
      },
      "outputs": [],
      "source": [
        "## Load packgae drive\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5LYc4pTTiut",
        "outputId": "fb424cdb-693b-4730-bbcd-c6cf5e6b17e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        " # Memberikan akses kepada Colab / Autorization\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Menentukan path untuk masing-masing folder\n",
        "path_crackles = os.path.join(direktori_utama, \"1_Crackles\")\n",
        "path_rhonchi = os.path.join(direktori_utama, \"2_Rhonchi\")\n",
        "\n",
        "# Mendefinisikan label\n",
        "labels = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "num_classes = len(labels)\n",
        "\n",
        "# Mendapatkan daftar file di masing-masing folder\n",
        "file_Crackles = os.listdir(path_crackles)\n",
        "file_Rhonchi = os.listdir(path_rhonchi)\n",
        "\n",
        "# Menampilkan jumlah file di masing-masing folder\n",
        "print(\"Jumlah file di folder Crackles:\", len(file_Crackles))\n",
        "print(\"Jumlah file di folder Rhonchi:\", len(file_Rhonchi))\n",
        "\n",
        "# Menampilkan jumlah kelas\n",
        "print(\"Jumlah kelas:\", num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwKoNsaqJBGZ",
        "outputId": "cf35328f-d770-4539-c493-57b9cf795173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah file di folder Crackles: 257\n",
            "Jumlah file di folder Rhonchi: 52\n",
            "Jumlah kelas: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan sinyal suara paru-paru Crackles\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "\n",
        "# Mengatur path file\n",
        "file_path = '/content/drive/MyDrive/Combination Dataset/Dataset/1_Crackles/Crackles_I1.wav'\n",
        "\n",
        "# Membaca file audio\n",
        "signal, sr = librosa.load(file_path, sr=None)  # sr=None untuk memastikan menggunakan sample rate asli\n",
        "\n",
        "# Menghitung waktu (dalam detik) untuk setiap sampel\n",
        "times = np.arange(len(signal)) / sr\n",
        "\n",
        "# Membuat plot\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.waveshow(signal, sr=sr)\n",
        "plt.xlabel('Time (Seconds)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('Lung Sound - Crackles')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nk3uZQwfLH2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan sinyal suara paru-paru Rhonchi\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "\n",
        "# Mengatur path file\n",
        "file_path = '/content/drive/MyDrive/Combination Dataset/Dataset/2_Rhonchi/Rhonchi_10_FHI.wav'\n",
        "\n",
        "# Membaca file audio\n",
        "signal, sr = librosa.load(file_path, sr=None)  # sr=None untuk memastikan menggunakan sample rate asli\n",
        "\n",
        "# Menghitung waktu (dalam detik) untuk setiap sampel\n",
        "times = np.arange(len(signal)) / sr\n",
        "\n",
        "# Membuat plot\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.waveshow(signal, sr=sr)\n",
        "plt.xlabel('Time (Seconds)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('Lung Sound - Rhonchi')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s_yDhhQwJjNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konversi Data Audio ke representasi tensor-float\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def convert_audio_to_tensor_float(input_dir, output_dir, folders):\n",
        "    for folder in folders:\n",
        "        input_path = os.path.join(input_dir, folder)\n",
        "        output_path = os.path.join(output_dir, folder)\n",
        "\n",
        "        if not os.path.exists(input_path):\n",
        "            print(f\"[SKIP] Folder tidak ditemukan: {input_path}\")\n",
        "            continue\n",
        "\n",
        "        os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "        success_count = 0\n",
        "        fail_count = 0\n",
        "\n",
        "        for filename in os.listdir(input_path):\n",
        "            if filename.lower().endswith('.wav'):\n",
        "                file_path = os.path.join(input_path, filename)\n",
        "\n",
        "                try:\n",
        "                    # Load audio\n",
        "                    audio_data, sr = librosa.load(file_path, sr=None)\n",
        "                    audio_tensor = np.array(audio_data, dtype=np.float32)\n",
        "\n",
        "                    # Save as .npy\n",
        "                    output_file_path = os.path.join(output_path, filename.replace('.wav', '.npy'))\n",
        "                    np.save(output_file_path, audio_tensor)\n",
        "\n",
        "                    success_count += 1\n",
        "                    print(f\"[OK] {folder}/{filename} -> {success_count}\")\n",
        "                except Exception as e:\n",
        "                    fail_count += 1\n",
        "                    print(f\"[ERROR] Gagal memproses {folder}/{filename}: {e}\")\n",
        "\n",
        "        print(f\"\\n📂 Folder {folder}: Sukses {success_count}, Gagal {fail_count}\\n\")\n",
        "\n",
        "# Path input/output dan daftar folder\n",
        "input_dir = \"/content/drive/MyDrive/Combination Dataset/Dataset\"\n",
        "output_dir = \"/content/drive/MyDrive/Combination Dataset/A_Konversi Data Audio ke representasi tensor-float\"\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "\n",
        "# Menjalankan proses konversi\n",
        "convert_audio_to_tensor_float(input_dir, output_dir, folders)\n",
        "\n",
        "print(\"✅ Proses konversi selesai untuk semua folder.\")\n"
      ],
      "metadata": {
        "id": "zryuQryhNLAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan Jumlah file audio yang berhasil dikonversi ke representasi tensor-float\n",
        "import os\n",
        "\n",
        "def count_converted_files(output_root, folders):\n",
        "    total_count = 0\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(output_root, folder)\n",
        "\n",
        "        if not os.path.exists(folder_path):\n",
        "            print(f\"[ERROR] Folder tidak ditemukan: {folder_path}\")\n",
        "            continue\n",
        "\n",
        "        file_count = len([f for f in os.listdir(folder_path) if f.endswith('.npy')])\n",
        "        total_count += file_count\n",
        "\n",
        "        print(f\"{folder}: {file_count} file berhasil dikonversi\")\n",
        "\n",
        "    print(f\"\\n🔢 Total file .npy yang berhasil dikonversi dari semua folder: {total_count} file\")\n",
        "\n",
        "# Path output dan nama folder\n",
        "output_root = \"/content/drive/MyDrive/Combination Dataset/A_Konversi Data Audio ke representasi tensor-float\"\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "\n",
        "# Hitung dan tampilkan jumlah file .npy per folder\n",
        "count_converted_files(output_root, folders)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew0mjxcTN_9n",
        "outputId": "1995de78-521d-4cfe-ab82-799bee547a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1_Crackles: 256 file berhasil dikonversi\n",
            "2_Rhonchi: 52 file berhasil dikonversi\n",
            "\n",
            "🔢 Total file .npy yang berhasil dikonversi dari semua folder: 308 file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "!apt-get install ffmpeg -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M052FT-_v95D",
        "outputId": "2c25131e-4f6d-4028-aa06-7972e9b0a9f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Frekuensi sampling 16kHz\n",
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from pydub import AudioSegment\n",
        "\n",
        "\n",
        "def resample_audio(file_path, target_sampling_rate=16000):\n",
        "    try:\n",
        "        audio, original_sampling_rate = librosa.load(file_path, sr=None, mono=True)\n",
        "        resampled_audio = librosa.resample(audio, orig_sr=original_sampling_rate, target_sr=target_sampling_rate)\n",
        "        return resampled_audio\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Librosa gagal baca {file_path}, mencoba pydub...\")\n",
        "\n",
        "        try:\n",
        "            audio = AudioSegment.from_file(file_path)\n",
        "            audio = audio.set_channels(1).set_frame_rate(target_sampling_rate)\n",
        "            samples = np.array(audio.get_array_of_samples()).astype(np.float32)\n",
        "            samples /= np.iinfo(audio.array_type).max\n",
        "            return samples\n",
        "        except Exception as e2:\n",
        "            print(f\"[ERROR] Pydub juga gagal baca {file_path}: {e2}\")\n",
        "            return None\n",
        "\n",
        "# Paths\n",
        "base_path = \"/content/drive/MyDrive/Combination Dataset/Dataset\"\n",
        "processed_path = \"/content/drive/MyDrive/Combination Dataset/B_Frekuensi sampling 16kHz\"\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "\n",
        "# Tracking\n",
        "total_sukses = 0\n",
        "total_gagal = 0\n",
        "\n",
        "for folder in folders:\n",
        "    input_folder = os.path.join(base_path, folder)\n",
        "    output_folder = os.path.join(processed_path, folder)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    audio_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.wav', '.mp3'))]\n",
        "    jumlah_disampling = 0\n",
        "    jumlah_dilewati = 0\n",
        "\n",
        "    for audio_file in audio_files:\n",
        "        file_path = os.path.join(input_folder, audio_file)\n",
        "        output_filename = os.path.splitext(audio_file)[0] + \".wav\"\n",
        "        output_path = os.path.join(output_folder, output_filename)\n",
        "\n",
        "        resampled_audio = resample_audio(file_path, target_sampling_rate=16000)\n",
        "        if resampled_audio is None:\n",
        "            jumlah_dilewati += 1\n",
        "            continue\n",
        "\n",
        "        sf.write(output_path, resampled_audio, 16000)\n",
        "        jumlah_disampling += 1\n",
        "\n",
        "    total_sukses += jumlah_disampling\n",
        "    total_gagal += jumlah_dilewati\n",
        "\n",
        "    print(f\"\\n📁 Folder '{folder}':\")\n",
        "    print(f\"   ✅ Disampling: {jumlah_disampling}\")\n",
        "    print(f\"   ❌ Dilewati (gagal): {jumlah_dilewati}\")\n",
        "\n",
        "print(f\"\\n📊 Total:\")\n",
        "print(f\"   ✅ Berhasil: {total_sukses}\")\n",
        "print(f\"   ❌ Gagal: {total_gagal}\")\n"
      ],
      "metadata": {
        "id": "uJS7NbOwvXkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengubah file .wav menjadi gambar Mel Spectrogram per kelas\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm  # Untuk progress bar\n",
        "\n",
        "# Direktori sumber dan tujuan\n",
        "source_dir = '/content/drive/MyDrive/Combination Dataset/B_Frekuensi sampling 16kHz'\n",
        "target_dir = '/content/drive/MyDrive/Combination Dataset/C_Mel Spectogram'\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "\n",
        "# Membuat folder tujuan utama jika belum ada\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "def create_mel_spectrogram(file_path, save_path):\n",
        "    try:\n",
        "        # Load file audio\n",
        "        y, sr = librosa.load(file_path)\n",
        "        # Konversi ke Mel Spectrogram\n",
        "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
        "        S_DB = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "        # Simpan sebagai gambar PNG\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        librosa.display.specshow(S_DB, sr=sr, x_axis='time', y_axis='mel')\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.title('Mel Spectrogram')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Gagal memproses {file_path}: {e}\")\n",
        "\n",
        "# Loop tiap folder kelas\n",
        "for folder in folders:\n",
        "    class_source_dir = os.path.join(source_dir, folder)\n",
        "    class_target_dir = os.path.join(target_dir, folder)\n",
        "    os.makedirs(class_target_dir, exist_ok=True)\n",
        "\n",
        "    # List semua file .wav dalam folder kelas\n",
        "    wav_files = [f for f in os.listdir(class_source_dir) if f.endswith('.wav')]\n",
        "\n",
        "    print(f\"Memproses folder: {folder} ({len(wav_files)} file)\")\n",
        "    for filename in tqdm(wav_files, desc=f\"Processing {folder}\"):\n",
        "        source_file_path = os.path.join(class_source_dir, filename)\n",
        "        target_file_path = os.path.join(class_target_dir, os.path.splitext(filename)[0] + '.png')\n",
        "        create_mel_spectrogram(source_file_path, target_file_path)\n",
        "\n",
        "print(\"Konversi selesai.\")\n"
      ],
      "metadata": {
        "id": "qhd1iltOy9-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan jumlah file pada kelas Mel Spectogram\n",
        "import os\n",
        "\n",
        "# Path dasar ke dataset\n",
        "base_path = \"/content/drive/MyDrive/Combination Dataset/C_Mel Spectogram\"\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "\n",
        "# Fungsi menghitung jumlah file dalam folder\n",
        "def count_files_in_folder(folder_path):\n",
        "    try:\n",
        "        return len([\n",
        "            name for name in os.listdir(folder_path)\n",
        "            if os.path.isfile(os.path.join(folder_path, name))\n",
        "        ])\n",
        "    except FileNotFoundError:\n",
        "        return 0\n",
        "\n",
        "# Hitung dan tampilkan jumlah file untuk masing-masing kelas\n",
        "for folder in folders:\n",
        "    full_path = os.path.join(base_path, folder)\n",
        "    jumlah_file = count_files_in_folder(full_path)\n",
        "    print(f\"Jumlah file di {folder}: {jumlah_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH1evdSL0_0K",
        "outputId": "1586c9b8-ca62-4282-bb2a-a66ca631496d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah file di 1_Crackles: 256\n",
            "Jumlah file di 2_Rhonchi: 52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Augmentasi dengan target 514\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Fungsi SpecAugment\n",
        "def time_warp(spec, W=5):\n",
        "    # Untuk menjaga kesederhanaan, diabaikan dulu\n",
        "    return spec\n",
        "\n",
        "def freq_mask(spec, F=30, num_masks=1):\n",
        "    cloned = spec.copy()\n",
        "    num_mel_channels = cloned.shape[0]\n",
        "    for _ in range(num_masks):\n",
        "        f = np.random.uniform(0, F)\n",
        "        f_zero = int(np.random.uniform(0, num_mel_channels - f))\n",
        "        cloned[f_zero:f_zero + int(f)] = 0\n",
        "    return cloned\n",
        "\n",
        "def time_mask(spec, T=40, num_masks=1):\n",
        "    cloned = spec.copy()\n",
        "    len_spectro = cloned.shape[1]\n",
        "    for _ in range(num_masks):\n",
        "        t = np.random.uniform(0, T)\n",
        "        t_zero = int(np.random.uniform(0, len_spectro - t))\n",
        "        cloned[:, t_zero:t_zero + int(t)] = 0\n",
        "    return cloned\n",
        "\n",
        "def spec_augment(spec, W=5, F=30, T=40, num_freq_masks=1, num_time_masks=1):\n",
        "    spec = time_warp(spec, W)\n",
        "    spec = freq_mask(spec, F, num_freq_masks)\n",
        "    spec = time_mask(spec, T, num_time_masks)\n",
        "    return spec\n",
        "\n",
        "# Path dan parameter\n",
        "input_folder = '/content/drive/MyDrive/Combination Dataset/C_Mel Spectogram'\n",
        "output_folder = '/content/drive/MyDrive/Combination Dataset/D_Augmentasi data dengan SpecAugment'\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "target_count = 514\n",
        "\n",
        "# Proses augmentasi per kelas\n",
        "for folder in folders:\n",
        "    input_class_folder = os.path.join(input_folder, folder)\n",
        "    output_class_folder = os.path.join(output_folder, folder)\n",
        "    os.makedirs(output_class_folder, exist_ok=True)\n",
        "\n",
        "    # Salin semua file PNG dari input ke output\n",
        "    for file_name in os.listdir(input_class_folder):\n",
        "        src = os.path.join(input_class_folder, file_name)\n",
        "        dst = os.path.join(output_class_folder, file_name)\n",
        "        if os.path.isfile(src) and file_name.endswith('.png'):\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "    # Hitung jumlah file saat ini\n",
        "    current_files = [f for f in os.listdir(output_class_folder) if f.endswith('.png')]\n",
        "    current_count = len(current_files)\n",
        "\n",
        "    # Augmentasi jika jumlah file belum mencapai target\n",
        "    if current_count < target_count:\n",
        "        print(f\"[INFO] Augmentasi kelas {folder}: {current_count} -> {target_count}\")\n",
        "        while current_count < target_count:\n",
        "            file_name = random.choice(current_files)\n",
        "            full_file_name = os.path.join(output_class_folder, file_name)\n",
        "\n",
        "            mel_spec = plt.imread(full_file_name)\n",
        "            augmented_spec = spec_augment(mel_spec)\n",
        "\n",
        "            new_file_name = f\"aug_{current_count}.png\"\n",
        "            output_file = os.path.join(output_class_folder, new_file_name)\n",
        "\n",
        "            plt.imsave(output_file, augmented_spec, cmap='viridis')\n",
        "            current_count += 1\n",
        "\n",
        "    print(f\"[INFO] Total akhir file kelas {folder}: {current_count} file\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D0qPxtO35oB",
        "outputId": "92b8475b-c458-446a-c084-773aae16c475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Augmentasi kelas 1_Crackles: 256 -> 514\n",
            "[INFO] Total akhir file kelas 1_Crackles: 514 file\n",
            "\n",
            "[INFO] Augmentasi kelas 2_Rhonchi: 52 -> 514\n",
            "[INFO] Total akhir file kelas 2_Rhonchi: 514 file\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klZpmXi3aB4e",
        "outputId": "985e3acb-706c-47a2-d6f4-23e76603240f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.11/dist-packages (0.16.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_hub) (2.19.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (5.2.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow tensorflow_hub librosa scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UzGLqBJSz0O",
        "outputId": "84cdc60e-aad8-480d-b2ff-18069b8f8d3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.11/dist-packages (0.16.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub) (5.29.4)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub) (2.19.0)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19 in /usr/local/lib/python3.11/dist-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (25.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-hub\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer learning with ResNet50\n",
        "# 10 Fol Cross Validation\n",
        "# Setiap Fold selesai dan berhenti, jika running lagi secara manual ke fold berikutnya.\n",
        "# Menampilkan Accuracy, Precision, Recall, F1-score, AUC\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# Path dataset dan folder\n",
        "data_dir = '/content/drive/MyDrive/Combination Dataset/D_Augmentasi data dengan SpecAugment'\n",
        "output_dir = '/content/drive/MyDrive/Combination Dataset/E_10 Fold Cross Validation'\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "progress_file = os.path.join(output_dir, 'progress.txt')\n",
        "\n",
        "def load_dataset(data_dir, folders):\n",
        "    X, y = [] , []\n",
        "    for label, folder in enumerate(folders):\n",
        "        folder_path = os.path.join(data_dir, folder)\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            try:\n",
        "                img = Image.open(file_path).convert('RGB')\n",
        "                img = img.resize((224, 224))\n",
        "                img_array = np.array(img)\n",
        "                img_array = preprocess_input(img_array)\n",
        "                X.append(img_array)\n",
        "                y.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {file_name}: {e}\")\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def build_finetuned_resnet(num_classes):\n",
        "    base_model = ResNet50(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "    for layer in base_model.layers[-10:]:\n",
        "        layer.trainable = True\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.6)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.6)(x)\n",
        "    output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def save_progress(fold_index):\n",
        "    with open(progress_file, 'w') as f:\n",
        "        f.write(str(fold_index))\n",
        "\n",
        "def load_progress():\n",
        "    if os.path.exists(progress_file):\n",
        "        with open(progress_file, 'r') as f:\n",
        "            return int(f.read().strip())\n",
        "    return 0\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_dataset(data_dir, folders)\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "num_classes = 2\n",
        "last_completed_fold = load_progress()\n",
        "metrics = {'fold': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1_score': [], 'confusion_matrix': []}\n",
        "\n",
        "start_time = time.time()\n",
        "fold_index = 1\n",
        "for train_idx, val_idx in kf.split(X):\n",
        "    if fold_index <= last_completed_fold:\n",
        "        fold_index += 1\n",
        "        continue\n",
        "\n",
        "    print(f'Starting Fold {fold_index}...')\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=32, shuffle=True)\n",
        "    val_generator = ImageDataGenerator().flow(X_val, y_val, batch_size=32, shuffle=False)\n",
        "\n",
        "    model = build_finetuned_resnet(num_classes=num_classes)\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7),\n",
        "        ModelCheckpoint(filepath=os.path.join(output_dir, f'best_model_fold_{fold_index}.h5'), save_best_only=True)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(train_generator, validation_data=val_generator, epochs=50, callbacks=callbacks)\n",
        "\n",
        "    y_pred = np.argmax(model.predict(X_val), axis=1)\n",
        "\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    prec = precision_score(y_val, y_pred, average='macro', zero_division=0)\n",
        "    rec = recall_score(y_val, y_pred, average='macro', zero_division=0)\n",
        "    f1 = f1_score(y_val, y_pred, average='macro', zero_division=0)\n",
        "    cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "    metrics['fold'].append(fold_index)\n",
        "    metrics['accuracy'].append(acc)\n",
        "    metrics['precision'].append(prec)\n",
        "    metrics['recall'].append(rec)\n",
        "    metrics['f1_score'].append(f1)\n",
        "    metrics['confusion_matrix'].append(cm)\n",
        "\n",
        "    print(f\"Fold {fold_index} - Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-score: {f1:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Crackles\", \"Rhonchi\"])\n",
        "    disp.plot(cmap='Blues', values_format='d', ax=plt.gca())\n",
        "    plt.title(f'Confusion Matrix for Fold {fold_index}')\n",
        "    plt.show()\n",
        "\n",
        "    model.save(os.path.join(output_dir, f'model_fold_{fold_index}.h5'))\n",
        "    save_progress(fold_index)\n",
        "    print(f\"Fold {fold_index} selesai. Progres disimpan.\")\n",
        "\n",
        "    fold_index += 1\n",
        "\n",
        "# Simpan ke CSV\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "metrics_df.to_csv(os.path.join(output_dir, 'cross_validation_metrics.csv'), index=False)\n",
        "\n",
        "print(\"Cross-validation selesai.\")\n",
        "end_time = time.time()\n",
        "print(f\"\\nTotal waktu eksekusi: {end_time - start_time:.2f} detik\")\n"
      ],
      "metadata": {
        "id": "VLuPQgjQ6I6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow\n"
      ],
      "metadata": {
        "id": "pENd7PWpedQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9582a0-dc9c-4706-d42b-53bb7bb4c592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-io\n",
        "import tensorflow_io as tfio\n"
      ],
      "metadata": {
        "id": "nHK0pKkbhLLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dacd065a-7eca-4db2-a45f-e70bb490fb50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-io\n",
            "  Downloading tensorflow_io-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-io) (0.37.1)\n",
            "Downloading tensorflow_io-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-io\n",
            "Successfully installed tensorflow-io-0.37.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
            "caused by: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutex6unlockEv']\n",
            "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
            "/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
            "caused by: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZN3tsl7strings13safe_strtou64ESt17basic_string_viewIcSt11char_traitsIcEEPm']\n",
            "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bK2R9nNljInQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, MaxPooling2D,\n",
        "    BatchNormalization, Dropout,\n",
        "    GlobalAveragePooling2D, Dense\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.callbacks import (\n",
        "    EarlyStopping, ModelCheckpoint,\n",
        "    ReduceLROnPlateau, CSVLogger\n",
        ")\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score,\n",
        "    recall_score, f1_score,\n",
        "    confusion_matrix, ConfusionMatrixDisplay\n",
        ")\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "# ============================\n",
        "# PATH SETUP\n",
        "# ============================\n",
        "data_dir = '/content/drive/MyDrive/Combination Dataset/D_Augmentasi data dengan SpecAugment'\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "output_dir = '/content/drive/MyDrive/Combination Dataset/Model/CNN_V3'\n",
        "\n",
        "model_path = os.path.join(output_dir, 'last_epoch_model.keras')\n",
        "best_model_path = os.path.join(output_dir, 'best_model.keras')\n",
        "final_model_path = os.path.join(output_dir, 'final_model.keras')\n",
        "log_path = os.path.join(output_dir, 'training_log.csv')\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ============================\n",
        "# LOAD DATASET\n",
        "# ============================\n",
        "def load_dataset(data_dir, folders):\n",
        "    X, y = [], []\n",
        "    for label, folder in enumerate(folders):\n",
        "        folder_path = os.path.join(data_dir, folder)\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            try:\n",
        "                img = Image.open(file_path).convert('RGB')\n",
        "                img = img.resize((224, 224))\n",
        "                img_array = preprocess_input(np.array(img))\n",
        "                X.append(img_array)\n",
        "                y.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {file_name}: {e}\")\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = load_dataset(data_dir, folders)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# CNN MODEL V3\n",
        "# ============================\n",
        "def build_better_cnn(input_shape=(224, 224, 3), num_classes=2):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same',\n",
        "               kernel_regularizer=regularizers.l2(1e-4))(inputs)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
        "               kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
        "               kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Classifier Head\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# ============================\n",
        "# BUILD OR LOAD MODEL\n",
        "# ============================\n",
        "initial_epoch = 0\n",
        "if os.path.exists(model_path):\n",
        "    print(\"✅ Loading model from last checkpoint...\")\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "else:\n",
        "    print(\"🚧 No previous model found. Building CNN V3 model...\")\n",
        "    model = build_better_cnn()\n",
        "    model.compile(optimizer=Adamax(learning_rate=5e-5),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "if os.path.exists(log_path) and os.path.getsize(log_path) > 0:\n",
        "    df = pd.read_csv(log_path)\n",
        "    initial_epoch = len(df)\n",
        "    print(f\"🔁 Resuming from epoch {initial_epoch}\")\n",
        "else:\n",
        "    print(\"📭 Log file is empty or not found. Starting from epoch 0.\")\n",
        "\n",
        "# ============================\n",
        "# CALLBACKS\n",
        "# ============================\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7),\n",
        "    ModelCheckpoint(best_model_path, save_best_only=True),\n",
        "    ModelCheckpoint(model_path, save_best_only=False),\n",
        "    CSVLogger(log_path, append=os.path.exists(log_path) and os.path.getsize(log_path) > 0)\n",
        "]\n",
        "\n",
        "# ============================\n",
        "# TRAINING\n",
        "# ============================\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=75,\n",
        "    initial_epoch=initial_epoch,\n",
        "    callbacks=callbacks,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# EVALUATION\n",
        "# ============================\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(f\"Accuracy : {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall   : {recall:.4f}\")\n",
        "print(f\"F1-score : {f1:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=folders)\n",
        "disp.plot(cmap='Blues', values_format='d', ax=plt.gca())\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# ============================\n",
        "# SAVE MODEL & METRICS\n",
        "# ============================\n",
        "model.save(final_model_path)\n",
        "pd.DataFrame({\n",
        "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"],\n",
        "    \"Value\": [accuracy, precision, recall, f1]\n",
        "}).to_csv(os.path.join(output_dir, 'evaluation_metrics.csv'), index=False)\n",
        "\n",
        "print(\"✅ Training & evaluation selesai. Model dan hasil disimpan.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D4361tcfQcH2",
        "outputId": "64c93a39-6dc9-46e8-e12f-fc6832d0d696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loading model from last checkpoint...\n",
            "🔁 Resuming from epoch 5\n",
            "Epoch 6/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 159ms/step - accuracy: 0.8793 - loss: 0.3692 - val_accuracy: 0.7427 - val_loss: 0.5142 - learning_rate: 5.0000e-05\n",
            "Epoch 7/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.8567 - loss: 0.3949 - val_accuracy: 0.7816 - val_loss: 0.4619 - learning_rate: 5.0000e-05\n",
            "Epoch 8/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.8752 - loss: 0.3550 - val_accuracy: 0.8204 - val_loss: 0.4223 - learning_rate: 5.0000e-05\n",
            "Epoch 9/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8760 - loss: 0.3401 - val_accuracy: 0.8447 - val_loss: 0.3924 - learning_rate: 5.0000e-05\n",
            "Epoch 10/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.8782 - loss: 0.3511 - val_accuracy: 0.8689 - val_loss: 0.3692 - learning_rate: 5.0000e-05\n",
            "Epoch 11/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8634 - loss: 0.3548 - val_accuracy: 0.8835 - val_loss: 0.3532 - learning_rate: 5.0000e-05\n",
            "Epoch 12/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8614 - loss: 0.3473 - val_accuracy: 0.8981 - val_loss: 0.3432 - learning_rate: 5.0000e-05\n",
            "Epoch 13/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.8747 - loss: 0.3132 - val_accuracy: 0.8981 - val_loss: 0.3287 - learning_rate: 5.0000e-05\n",
            "Epoch 14/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.8894 - loss: 0.3098 - val_accuracy: 0.9029 - val_loss: 0.3176 - learning_rate: 5.0000e-05\n",
            "Epoch 15/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.8963 - loss: 0.2903 - val_accuracy: 0.9029 - val_loss: 0.3077 - learning_rate: 5.0000e-05\n",
            "Epoch 16/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.8973 - loss: 0.2887 - val_accuracy: 0.9078 - val_loss: 0.3004 - learning_rate: 5.0000e-05\n",
            "Epoch 17/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8991 - loss: 0.2781 - val_accuracy: 0.9126 - val_loss: 0.2951 - learning_rate: 5.0000e-05\n",
            "Epoch 18/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.9159 - loss: 0.2577 - val_accuracy: 0.9078 - val_loss: 0.2812 - learning_rate: 5.0000e-05\n",
            "Epoch 19/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.8980 - loss: 0.2739 - val_accuracy: 0.9078 - val_loss: 0.2737 - learning_rate: 5.0000e-05\n",
            "Epoch 20/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.9157 - loss: 0.2591 - val_accuracy: 0.9175 - val_loss: 0.2678 - learning_rate: 5.0000e-05\n",
            "Epoch 21/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.8819 - loss: 0.2902 - val_accuracy: 0.9175 - val_loss: 0.2625 - learning_rate: 5.0000e-05\n",
            "Epoch 22/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.8964 - loss: 0.2694 - val_accuracy: 0.9126 - val_loss: 0.2557 - learning_rate: 5.0000e-05\n",
            "Epoch 23/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.9070 - loss: 0.2650 - val_accuracy: 0.9126 - val_loss: 0.2531 - learning_rate: 5.0000e-05\n",
            "Epoch 24/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.9036 - loss: 0.2719 - val_accuracy: 0.9175 - val_loss: 0.2438 - learning_rate: 5.0000e-05\n",
            "Epoch 25/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.9113 - loss: 0.2458 - val_accuracy: 0.9175 - val_loss: 0.2411 - learning_rate: 5.0000e-05\n",
            "Epoch 26/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.9070 - loss: 0.2720 - val_accuracy: 0.9175 - val_loss: 0.2378 - learning_rate: 5.0000e-05\n",
            "Epoch 27/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.9031 - loss: 0.2583 - val_accuracy: 0.9223 - val_loss: 0.2296 - learning_rate: 5.0000e-05\n",
            "Epoch 28/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.9236 - loss: 0.2435 - val_accuracy: 0.9175 - val_loss: 0.2297 - learning_rate: 5.0000e-05\n",
            "Epoch 29/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.9158 - loss: 0.2504 - val_accuracy: 0.9320 - val_loss: 0.2210 - learning_rate: 5.0000e-05\n",
            "Epoch 30/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9128 - loss: 0.2397 - val_accuracy: 0.9175 - val_loss: 0.2221 - learning_rate: 5.0000e-05\n",
            "Epoch 31/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.9087 - loss: 0.2435 - val_accuracy: 0.9175 - val_loss: 0.2192 - learning_rate: 5.0000e-05\n",
            "Epoch 32/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.9352 - loss: 0.2254 - val_accuracy: 0.9175 - val_loss: 0.2143 - learning_rate: 5.0000e-05\n",
            "Epoch 33/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.9387 - loss: 0.2218 - val_accuracy: 0.9175 - val_loss: 0.2131 - learning_rate: 5.0000e-05\n",
            "Epoch 34/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.9369 - loss: 0.2080 - val_accuracy: 0.9175 - val_loss: 0.2189 - learning_rate: 5.0000e-05\n",
            "Epoch 35/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.9126 - loss: 0.2336 - val_accuracy: 0.9320 - val_loss: 0.2002 - learning_rate: 5.0000e-05\n",
            "Epoch 36/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9292 - loss: 0.2293 - val_accuracy: 0.9175 - val_loss: 0.2157 - learning_rate: 5.0000e-05\n",
            "Epoch 37/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.9130 - loss: 0.2276 - val_accuracy: 0.9175 - val_loss: 0.2132 - learning_rate: 5.0000e-05\n",
            "Epoch 38/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9228 - loss: 0.2059 - val_accuracy: 0.9223 - val_loss: 0.2069 - learning_rate: 5.0000e-05\n",
            "Epoch 39/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.9431 - loss: 0.1911 - val_accuracy: 0.9223 - val_loss: 0.2037 - learning_rate: 1.0000e-05\n",
            "Epoch 40/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9317 - loss: 0.2061 - val_accuracy: 0.9223 - val_loss: 0.2023 - learning_rate: 1.0000e-05\n",
            "Epoch 41/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9353 - loss: 0.2128 - val_accuracy: 0.9175 - val_loss: 0.1986 - learning_rate: 1.0000e-05\n",
            "Epoch 42/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.9417 - loss: 0.1975 - val_accuracy: 0.9320 - val_loss: 0.1940 - learning_rate: 1.0000e-05\n",
            "Epoch 43/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9605 - loss: 0.1784 - val_accuracy: 0.9272 - val_loss: 0.1952 - learning_rate: 1.0000e-05\n",
            "Epoch 44/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9366 - loss: 0.2161 - val_accuracy: 0.9175 - val_loss: 0.1973 - learning_rate: 1.0000e-05\n",
            "Epoch 45/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.9341 - loss: 0.2145 - val_accuracy: 0.9272 - val_loss: 0.1940 - learning_rate: 1.0000e-05\n",
            "Epoch 46/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.9444 - loss: 0.1945 - val_accuracy: 0.9272 - val_loss: 0.1944 - learning_rate: 2.0000e-06\n",
            "Epoch 47/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.9494 - loss: 0.1898 - val_accuracy: 0.9223 - val_loss: 0.1947 - learning_rate: 2.0000e-06\n",
            "Epoch 48/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9375 - loss: 0.2075 - val_accuracy: 0.9223 - val_loss: 0.1949 - learning_rate: 2.0000e-06\n",
            "Epoch 49/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9342 - loss: 0.2125 - val_accuracy: 0.9223 - val_loss: 0.1949 - learning_rate: 4.0000e-07\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Evaluation Metrics:\n",
            "Accuracy : 0.9320\n",
            "Precision: 0.9361\n",
            "Recall   : 0.9320\n",
            "F1-score : 0.9319\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training & evaluation selesai. Model dan hasil disimpan.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}