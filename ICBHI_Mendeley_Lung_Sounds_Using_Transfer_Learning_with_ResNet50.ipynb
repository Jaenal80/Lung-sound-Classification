{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g25PLQ2Ioqff"
      },
      "outputs": [],
      "source": [
        "# Enhancing Lung Sound Classification Using Transfer Learning with ResNet50.\n",
        "# Berikut langkah-langkah yang dilakukan pada penelitian lung sounds.\n",
        "# 1. Pengumpulan Dataset:\n",
        "#    Lokasi: /content/drive/MyDrive/Combination Dataset/Dataset\n",
        "#    Label dataset: Rhonchi, Crackles\n",
        "# Jumlah file di folder Rhonchi : 52   (sumber mendeley data)\n",
        "# Jumlah file di folder Crackles : 257 (sumber ICBHI)\n",
        "# Jumlah kelas: 2\n",
        "# 2. Pra-pemrosesan:\n",
        "#    a. Konversi Data Audio ke representasi tensor-float\n",
        "#    b. Frekuensi sampling dengan target sampling rate sebesar 16 kHz (untuk mencapai keseragaman dan standarisasi).\n",
        "#    c. Transformasi ke Mel Spectrogram\n",
        "# 3. Augmentasi data dari Google Brain's SpecAugment\".\n",
        "# Hasil :\n",
        "# Jumlah data untuk 1_Crackles : 514\n",
        "# Jumlah data untuk 2_Rhonchi: 514\n",
        "# 4. 10 Fold Cros Validation\n",
        "# 5. Menjalankan menggunakan Transfer Learning with Model ResNet50\n",
        "# evaluasi metrik seperti accuracy, precision, recall, f1_score, auc dan confusion matrix.\n",
        "#===============================================================================================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8RBeelGTVg6",
        "outputId": "77624622-54f5-4c35-f8e5-4841e0947f7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.2)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (5.2.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tensorflow_hub\n",
            "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow_hub)\n",
            "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (5.2.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
            "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, google-pasta, tensorboard, astunparse, tensorflow, tf-keras, tensorflow_hub\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 tensorflow_hub-0.16.1 tf-keras-2.19.0 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        }
      ],
      "source": [
        "#Import library yang diperlukan\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "!pip install librosa\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "!pip install soundfile\n",
        "import librosa.display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "#import pywt\n",
        "from scipy import signal\n",
        "!pip install tensorflow tensorflow_hub librosa scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uP9gDwoTduB"
      },
      "outputs": [],
      "source": [
        "# Load packgae drive\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5LYc4pTTiut",
        "outputId": "33d8969e-289d-46a1-b0a6-d6ea655db725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        " # Memberikan akses kepada Colab / Autorization\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Menentukan path untuk masing-masing folder\n",
        "path_crackles = os.path.join(direktori_utama, \"1_Crackles\")\n",
        "path_rhonchi = os.path.join(direktori_utama, \"2_Rhonchi\")\n",
        "\n",
        "# Mendefinisikan label\n",
        "labels = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "num_classes = len(labels)\n",
        "\n",
        "# Mendapatkan daftar file di masing-masing folder\n",
        "file_Crackles = os.listdir(path_crackles)\n",
        "file_Rhonchi = os.listdir(path_rhonchi)\n",
        "\n",
        "# Menampilkan jumlah file di masing-masing folder\n",
        "print(\"Jumlah file di folder Crackles:\", len(file_Crackles))\n",
        "print(\"Jumlah file di folder Rhonchi:\", len(file_Rhonchi))\n",
        "\n",
        "# Menampilkan jumlah kelas\n",
        "print(\"Jumlah kelas:\", num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwKoNsaqJBGZ",
        "outputId": "cf35328f-d770-4539-c493-57b9cf795173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah file di folder Crackles: 257\n",
            "Jumlah file di folder Rhonchi: 52\n",
            "Jumlah kelas: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan sinyal suara paru-paru Crackles\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "\n",
        "# Mengatur path file\n",
        "file_path = '/content/drive/MyDrive/Combination Dataset/Dataset/1_Crackles/Crackles_I1.wav'\n",
        "\n",
        "# Membaca file audio\n",
        "signal, sr = librosa.load(file_path, sr=None)  # sr=None untuk memastikan menggunakan sample rate asli\n",
        "\n",
        "# Menghitung waktu (dalam detik) untuk setiap sampel\n",
        "times = np.arange(len(signal)) / sr\n",
        "\n",
        "# Membuat plot\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.waveshow(signal, sr=sr)\n",
        "plt.xlabel('Time (Seconds)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('Lung Sound - Crackles')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nk3uZQwfLH2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan sinyal suara paru-paru Rhonchi\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "\n",
        "# Mengatur path file\n",
        "file_path = '/content/drive/MyDrive/Combination Dataset/Dataset/2_Rhonchi/Rhonchi_10_FHI.wav'\n",
        "\n",
        "# Membaca file audio\n",
        "signal, sr = librosa.load(file_path, sr=None)  # sr=None untuk memastikan menggunakan sample rate asli\n",
        "\n",
        "# Menghitung waktu (dalam detik) untuk setiap sampel\n",
        "times = np.arange(len(signal)) / sr\n",
        "\n",
        "# Membuat plot\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.waveshow(signal, sr=sr)\n",
        "plt.xlabel('Time (Seconds)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('Lung Sound - Rhonchi')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s_yDhhQwJjNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konversi Data Audio ke representasi tensor-float\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def convert_audio_to_tensor_float(input_dir, output_dir, folders):\n",
        "    for folder in folders:\n",
        "        input_path = os.path.join(input_dir, folder)\n",
        "        output_path = os.path.join(output_dir, folder)\n",
        "\n",
        "        if not os.path.exists(input_path):\n",
        "            print(f\"[SKIP] Folder tidak ditemukan: {input_path}\")\n",
        "            continue\n",
        "\n",
        "        os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "        success_count = 0\n",
        "        fail_count = 0\n",
        "\n",
        "        for filename in os.listdir(input_path):\n",
        "            if filename.lower().endswith('.wav'):\n",
        "                file_path = os.path.join(input_path, filename)\n",
        "\n",
        "                try:\n",
        "                    # Load audio\n",
        "                    audio_data, sr = librosa.load(file_path, sr=None)\n",
        "                    audio_tensor = np.array(audio_data, dtype=np.float32)\n",
        "\n",
        "                    # Save as .npy\n",
        "                    output_file_path = os.path.join(output_path, filename.replace('.wav', '.npy'))\n",
        "                    np.save(output_file_path, audio_tensor)\n",
        "\n",
        "                    success_count += 1\n",
        "                    print(f\"[OK] {folder}/{filename} -> {success_count}\")\n",
        "                except Exception as e:\n",
        "                    fail_count += 1\n",
        "                    print(f\"[ERROR] Gagal memproses {folder}/{filename}: {e}\")\n",
        "\n",
        "        print(f\"\\n📂 Folder {folder}: Sukses {success_count}, Gagal {fail_count}\\n\")\n",
        "\n",
        "# Path input/output dan daftar folder\n",
        "input_dir = \"/content/drive/MyDrive/Combination Dataset/Dataset\"\n",
        "output_dir = \"/content/drive/MyDrive/Combination Dataset/A_Konversi Data Audio ke representasi tensor-float\"\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "\n",
        "# Menjalankan proses konversi\n",
        "convert_audio_to_tensor_float(input_dir, output_dir, folders)\n",
        "\n",
        "print(\"✅ Proses konversi selesai untuk semua folder.\")\n"
      ],
      "metadata": {
        "id": "zryuQryhNLAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan Jumlah file audio yang berhasil dikonversi ke representasi tensor-float\n",
        "import os\n",
        "\n",
        "def count_converted_files(output_root, folders):\n",
        "    total_count = 0\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(output_root, folder)\n",
        "\n",
        "        if not os.path.exists(folder_path):\n",
        "            print(f\"[ERROR] Folder tidak ditemukan: {folder_path}\")\n",
        "            continue\n",
        "\n",
        "        file_count = len([f for f in os.listdir(folder_path) if f.endswith('.npy')])\n",
        "        total_count += file_count\n",
        "\n",
        "        print(f\"{folder}: {file_count} file berhasil dikonversi\")\n",
        "\n",
        "    print(f\"\\n🔢 Total file .npy yang berhasil dikonversi dari semua folder: {total_count} file\")\n",
        "\n",
        "# Path output dan nama folder\n",
        "output_root = \"/content/drive/MyDrive/Combination Dataset/A_Konversi Data Audio ke representasi tensor-float\"\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "\n",
        "# Hitung dan tampilkan jumlah file .npy per folder\n",
        "count_converted_files(output_root, folders)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew0mjxcTN_9n",
        "outputId": "1995de78-521d-4cfe-ab82-799bee547a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1_Crackles: 256 file berhasil dikonversi\n",
            "2_Rhonchi: 52 file berhasil dikonversi\n",
            "\n",
            "🔢 Total file .npy yang berhasil dikonversi dari semua folder: 308 file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "!apt-get install ffmpeg -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M052FT-_v95D",
        "outputId": "2c25131e-4f6d-4028-aa06-7972e9b0a9f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Frekuensi sampling 16kHz\n",
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from pydub import AudioSegment\n",
        "\n",
        "\n",
        "def resample_audio(file_path, target_sampling_rate=16000):\n",
        "    try:\n",
        "        audio, original_sampling_rate = librosa.load(file_path, sr=None, mono=True)\n",
        "        resampled_audio = librosa.resample(audio, orig_sr=original_sampling_rate, target_sr=target_sampling_rate)\n",
        "        return resampled_audio\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Librosa gagal baca {file_path}, mencoba pydub...\")\n",
        "\n",
        "        try:\n",
        "            audio = AudioSegment.from_file(file_path)\n",
        "            audio = audio.set_channels(1).set_frame_rate(target_sampling_rate)\n",
        "            samples = np.array(audio.get_array_of_samples()).astype(np.float32)\n",
        "            samples /= np.iinfo(audio.array_type).max\n",
        "            return samples\n",
        "        except Exception as e2:\n",
        "            print(f\"[ERROR] Pydub juga gagal baca {file_path}: {e2}\")\n",
        "            return None\n",
        "\n",
        "# Paths\n",
        "base_path = \"/content/drive/MyDrive/Combination Dataset/Dataset\"\n",
        "processed_path = \"/content/drive/MyDrive/Combination Dataset/B_Frekuensi sampling 16kHz\"\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "\n",
        "# Tracking\n",
        "total_sukses = 0\n",
        "total_gagal = 0\n",
        "\n",
        "for folder in folders:\n",
        "    input_folder = os.path.join(base_path, folder)\n",
        "    output_folder = os.path.join(processed_path, folder)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    audio_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.wav', '.mp3'))]\n",
        "    jumlah_disampling = 0\n",
        "    jumlah_dilewati = 0\n",
        "\n",
        "    for audio_file in audio_files:\n",
        "        file_path = os.path.join(input_folder, audio_file)\n",
        "        output_filename = os.path.splitext(audio_file)[0] + \".wav\"\n",
        "        output_path = os.path.join(output_folder, output_filename)\n",
        "\n",
        "        resampled_audio = resample_audio(file_path, target_sampling_rate=16000)\n",
        "        if resampled_audio is None:\n",
        "            jumlah_dilewati += 1\n",
        "            continue\n",
        "\n",
        "        sf.write(output_path, resampled_audio, 16000)\n",
        "        jumlah_disampling += 1\n",
        "\n",
        "    total_sukses += jumlah_disampling\n",
        "    total_gagal += jumlah_dilewati\n",
        "\n",
        "    print(f\"\\n📁 Folder '{folder}':\")\n",
        "    print(f\"   ✅ Disampling: {jumlah_disampling}\")\n",
        "    print(f\"   ❌ Dilewati (gagal): {jumlah_dilewati}\")\n",
        "\n",
        "print(f\"\\n📊 Total:\")\n",
        "print(f\"   ✅ Berhasil: {total_sukses}\")\n",
        "print(f\"   ❌ Gagal: {total_gagal}\")\n"
      ],
      "metadata": {
        "id": "uJS7NbOwvXkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengubah file .wav menjadi gambar Mel Spectrogram per kelas\n",
        "\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm  # Untuk progress bar\n",
        "\n",
        "# Direktori sumber dan tujuan\n",
        "source_dir = '/content/drive/MyDrive/Combination Dataset/B_Frekuensi sampling 16kHz'\n",
        "target_dir = '/content/drive/MyDrive/Combination Dataset/C_Mel Spectogram'\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "\n",
        "# Membuat folder tujuan utama jika belum ada\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "def create_mel_spectrogram(file_path, save_path):\n",
        "    try:\n",
        "        # Load file audio\n",
        "        y, sr = librosa.load(file_path)\n",
        "        # Konversi ke Mel Spectrogram\n",
        "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
        "        S_DB = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "        # Simpan sebagai gambar PNG\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        librosa.display.specshow(S_DB, sr=sr, x_axis='time', y_axis='mel')\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.title('Mel Spectrogram')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Gagal memproses {file_path}: {e}\")\n",
        "\n",
        "# Loop tiap folder kelas\n",
        "for folder in folders:\n",
        "    class_source_dir = os.path.join(source_dir, folder)\n",
        "    class_target_dir = os.path.join(target_dir, folder)\n",
        "    os.makedirs(class_target_dir, exist_ok=True)\n",
        "\n",
        "    # List semua file .wav dalam folder kelas\n",
        "    wav_files = [f for f in os.listdir(class_source_dir) if f.endswith('.wav')]\n",
        "\n",
        "    print(f\"Memproses folder: {folder} ({len(wav_files)} file)\")\n",
        "    for filename in tqdm(wav_files, desc=f\"Processing {folder}\"):\n",
        "        source_file_path = os.path.join(class_source_dir, filename)\n",
        "        target_file_path = os.path.join(class_target_dir, os.path.splitext(filename)[0] + '.png')\n",
        "        create_mel_spectrogram(source_file_path, target_file_path)\n",
        "\n",
        "print(\"Konversi selesai.\")\n"
      ],
      "metadata": {
        "id": "qhd1iltOy9-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan jumlah file pada kelas Mel Spectogram\n",
        "import os\n",
        "\n",
        "# Path dasar ke dataset\n",
        "base_path = \"/content/drive/MyDrive/Combination Dataset/C_Mel Spectogram\"\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "\n",
        "# Fungsi menghitung jumlah file dalam folder\n",
        "def count_files_in_folder(folder_path):\n",
        "    try:\n",
        "        return len([\n",
        "            name for name in os.listdir(folder_path)\n",
        "            if os.path.isfile(os.path.join(folder_path, name))\n",
        "        ])\n",
        "    except FileNotFoundError:\n",
        "        return 0\n",
        "\n",
        "# Hitung dan tampilkan jumlah file untuk masing-masing kelas\n",
        "for folder in folders:\n",
        "    full_path = os.path.join(base_path, folder)\n",
        "    jumlah_file = count_files_in_folder(full_path)\n",
        "    print(f\"Jumlah file di {folder}: {jumlah_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH1evdSL0_0K",
        "outputId": "1586c9b8-ca62-4282-bb2a-a66ca631496d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah file di 1_Crackles: 256\n",
            "Jumlah file di 2_Rhonchi: 52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Augmentasi dengan target 514\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Fungsi SpecAugment\n",
        "def time_warp(spec, W=5):\n",
        "    # Untuk menjaga kesederhanaan, diabaikan dulu\n",
        "    return spec\n",
        "\n",
        "def freq_mask(spec, F=30, num_masks=1):\n",
        "    cloned = spec.copy()\n",
        "    num_mel_channels = cloned.shape[0]\n",
        "    for _ in range(num_masks):\n",
        "        f = np.random.uniform(0, F)\n",
        "        f_zero = int(np.random.uniform(0, num_mel_channels - f))\n",
        "        cloned[f_zero:f_zero + int(f)] = 0\n",
        "    return cloned\n",
        "\n",
        "def time_mask(spec, T=40, num_masks=1):\n",
        "    cloned = spec.copy()\n",
        "    len_spectro = cloned.shape[1]\n",
        "    for _ in range(num_masks):\n",
        "        t = np.random.uniform(0, T)\n",
        "        t_zero = int(np.random.uniform(0, len_spectro - t))\n",
        "        cloned[:, t_zero:t_zero + int(t)] = 0\n",
        "    return cloned\n",
        "\n",
        "def spec_augment(spec, W=5, F=30, T=40, num_freq_masks=1, num_time_masks=1):\n",
        "    spec = time_warp(spec, W)\n",
        "    spec = freq_mask(spec, F, num_freq_masks)\n",
        "    spec = time_mask(spec, T, num_time_masks)\n",
        "    return spec\n",
        "\n",
        "# Path dan parameter\n",
        "input_folder = '/content/drive/MyDrive/Combination Dataset/C_Mel Spectogram'\n",
        "output_folder = '/content/drive/MyDrive/Combination Dataset/D_Augmentasi data dengan SpecAugment'\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "target_count = 514\n",
        "\n",
        "# Proses augmentasi per kelas\n",
        "for folder in folders:\n",
        "    input_class_folder = os.path.join(input_folder, folder)\n",
        "    output_class_folder = os.path.join(output_folder, folder)\n",
        "    os.makedirs(output_class_folder, exist_ok=True)\n",
        "\n",
        "    # Salin semua file PNG dari input ke output\n",
        "    for file_name in os.listdir(input_class_folder):\n",
        "        src = os.path.join(input_class_folder, file_name)\n",
        "        dst = os.path.join(output_class_folder, file_name)\n",
        "        if os.path.isfile(src) and file_name.endswith('.png'):\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "    # Hitung jumlah file saat ini\n",
        "    current_files = [f for f in os.listdir(output_class_folder) if f.endswith('.png')]\n",
        "    current_count = len(current_files)\n",
        "\n",
        "    # Augmentasi jika jumlah file belum mencapai target\n",
        "    if current_count < target_count:\n",
        "        print(f\"[INFO] Augmentasi kelas {folder}: {current_count} -> {target_count}\")\n",
        "        while current_count < target_count:\n",
        "            file_name = random.choice(current_files)\n",
        "            full_file_name = os.path.join(output_class_folder, file_name)\n",
        "\n",
        "            mel_spec = plt.imread(full_file_name)\n",
        "            augmented_spec = spec_augment(mel_spec)\n",
        "\n",
        "            new_file_name = f\"aug_{current_count}.png\"\n",
        "            output_file = os.path.join(output_class_folder, new_file_name)\n",
        "\n",
        "            plt.imsave(output_file, augmented_spec, cmap='viridis')\n",
        "            current_count += 1\n",
        "\n",
        "    print(f\"[INFO] Total akhir file kelas {folder}: {current_count} file\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D0qPxtO35oB",
        "outputId": "92b8475b-c458-446a-c084-773aae16c475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Augmentasi kelas 1_Crackles: 256 -> 514\n",
            "[INFO] Total akhir file kelas 1_Crackles: 514 file\n",
            "\n",
            "[INFO] Augmentasi kelas 2_Rhonchi: 52 -> 514\n",
            "[INFO] Total akhir file kelas 2_Rhonchi: 514 file\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klZpmXi3aB4e",
        "outputId": "d03ac9f8-b06f-4573-bd94-fd6d3c426db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.11/dist-packages (0.16.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_hub) (2.19.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (5.2.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow tensorflow_hub librosa scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UzGLqBJSz0O",
        "outputId": "edf963f4-7c1f-4aee-a816-40c1eb75776c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.11/dist-packages (0.16.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub) (5.29.4)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub) (2.19.0)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19 in /usr/local/lib/python3.11/dist-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (25.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-hub\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer learning with ResNet50\n",
        "# 10 Fol Cross Validation\n",
        "# Setiap Fold selesai dan berhenti, jika running lagi secara manual ke fold berikutnya.\n",
        "# Menampilkan Accuracy, Precision, Recall, F1-score, AUC\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# Path dataset dan folder\n",
        "data_dir = '/content/drive/MyDrive/Combination Dataset/D_Augmentasi data dengan SpecAugment'\n",
        "output_dir = '/content/drive/MyDrive/Combination Dataset/E_10 Fold Cross Validation'\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "progress_file = os.path.join(output_dir, 'progress.txt')\n",
        "\n",
        "def load_dataset(data_dir, folders):\n",
        "    X, y = [] , []\n",
        "    for label, folder in enumerate(folders):\n",
        "        folder_path = os.path.join(data_dir, folder)\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            try:\n",
        "                img = Image.open(file_path).convert('RGB')\n",
        "                img = img.resize((224, 224))\n",
        "                img_array = np.array(img)\n",
        "                img_array = preprocess_input(img_array)\n",
        "                X.append(img_array)\n",
        "                y.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {file_name}: {e}\")\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def build_finetuned_resnet(num_classes):\n",
        "    base_model = ResNet50(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "    for layer in base_model.layers[-10:]:\n",
        "        layer.trainable = True\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.6)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.6)(x)\n",
        "    output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def save_progress(fold_index):\n",
        "    with open(progress_file, 'w') as f:\n",
        "        f.write(str(fold_index))\n",
        "\n",
        "def load_progress():\n",
        "    if os.path.exists(progress_file):\n",
        "        with open(progress_file, 'r') as f:\n",
        "            return int(f.read().strip())\n",
        "    return 0\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_dataset(data_dir, folders)\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "num_classes = 2\n",
        "last_completed_fold = load_progress()\n",
        "metrics = {'fold': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1_score': [], 'confusion_matrix': []}\n",
        "\n",
        "start_time = time.time()\n",
        "fold_index = 1\n",
        "for train_idx, val_idx in kf.split(X):\n",
        "    if fold_index <= last_completed_fold:\n",
        "        fold_index += 1\n",
        "        continue\n",
        "\n",
        "    print(f'Starting Fold {fold_index}...')\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=32, shuffle=True)\n",
        "    val_generator = ImageDataGenerator().flow(X_val, y_val, batch_size=32, shuffle=False)\n",
        "\n",
        "    model = build_finetuned_resnet(num_classes=num_classes)\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7),\n",
        "        ModelCheckpoint(filepath=os.path.join(output_dir, f'best_model_fold_{fold_index}.h5'), save_best_only=True)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(train_generator, validation_data=val_generator, epochs=50, callbacks=callbacks)\n",
        "\n",
        "    y_pred = np.argmax(model.predict(X_val), axis=1)\n",
        "\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    prec = precision_score(y_val, y_pred, average='macro', zero_division=0)\n",
        "    rec = recall_score(y_val, y_pred, average='macro', zero_division=0)\n",
        "    f1 = f1_score(y_val, y_pred, average='macro', zero_division=0)\n",
        "    cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "    metrics['fold'].append(fold_index)\n",
        "    metrics['accuracy'].append(acc)\n",
        "    metrics['precision'].append(prec)\n",
        "    metrics['recall'].append(rec)\n",
        "    metrics['f1_score'].append(f1)\n",
        "    metrics['confusion_matrix'].append(cm)\n",
        "\n",
        "    print(f\"Fold {fold_index} - Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-score: {f1:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Crackles\", \"Rhonchi\"])\n",
        "    disp.plot(cmap='Blues', values_format='d', ax=plt.gca())\n",
        "    plt.title(f'Confusion Matrix for Fold {fold_index}')\n",
        "    plt.show()\n",
        "\n",
        "    model.save(os.path.join(output_dir, f'model_fold_{fold_index}.h5'))\n",
        "    save_progress(fold_index)\n",
        "    print(f\"Fold {fold_index} selesai. Progres disimpan.\")\n",
        "\n",
        "    fold_index += 1\n",
        "\n",
        "# Simpan ke CSV\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "metrics_df.to_csv(os.path.join(output_dir, 'cross_validation_metrics.csv'), index=False)\n",
        "\n",
        "print(\"Cross-validation selesai.\")\n",
        "end_time = time.time()\n",
        "print(f\"\\nTotal waktu eksekusi: {end_time - start_time:.2f} detik\")\n"
      ],
      "metadata": {
        "id": "VLuPQgjQ6I6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow\n"
      ],
      "metadata": {
        "id": "pENd7PWpedQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1202dfc-0a14-408b-f5dd-0a28197d4d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-io\n",
        "import tensorflow_io as tfio\n"
      ],
      "metadata": {
        "id": "nHK0pKkbhLLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a577aa-5513-4b98-b838-c4c8b166a5f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-io\n",
            "  Downloading tensorflow_io-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-io) (0.37.1)\n",
            "Downloading tensorflow_io-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-io\n",
            "Successfully installed tensorflow-io-0.37.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
            "caused by: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutex6unlockEv']\n",
            "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
            "/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
            "caused by: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZN3tsl7strings13safe_strtou64ESt17basic_string_viewIcSt11char_traitsIcEEPm']\n",
            "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bK2R9nNljInQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Menjalankan model Transfer Learning with ResNet50, dengan pembagian data latih 80% dan data uji 20%.\n",
        "# optimizer=Adamax Learning rate 0.00005\n",
        "# Menampilkan Accuracy, Precision, Recall, F1-score, serta visualisasi Confusion Matrix di layar google golab.\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path & setup\n",
        "data_dir = '/content/drive/MyDrive/Combination Dataset/D_Augmentasi data dengan SpecAugment'\n",
        "folders = [\"1_Crackles\", \"2_Rhonchi\"]\n",
        "output_dir = '/content/drive/MyDrive/Combination Dataset/F_Transfer Learning with ResNet50/Adamax'\n",
        "\n",
        "model_path = os.path.join(output_dir, 'last_epoch_model.keras')\n",
        "best_model_path = os.path.join(output_dir, 'best_model.keras')\n",
        "final_model_path = os.path.join(output_dir, 'final_model.keras')\n",
        "log_path = os.path.join(output_dir, 'training_log.csv')\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load image data from folders\n",
        "def load_dataset(data_dir, folders):\n",
        "    X, y = [], []\n",
        "    for label, folder in enumerate(folders):\n",
        "        folder_path = os.path.join(data_dir, folder)\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            try:\n",
        "                img = Image.open(file_path).convert('RGB')\n",
        "                img = img.resize((224, 224))\n",
        "                img_array = preprocess_input(np.array(img))\n",
        "                X.append(img_array)\n",
        "                y.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {file_name}: {e}\")\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = load_dataset(data_dir, folders)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Build ResNet50 model\n",
        "def build_finetuned_resnet():\n",
        "    base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "    for layer in base_model.layers[-10:]:\n",
        "        layer.trainable = True\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.6)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.6)(x)\n",
        "    output = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
        "    model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer=Adamax(learning_rate=5e-5),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Data generator\n",
        "train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=32)\n",
        "test_generator = ImageDataGenerator().flow(X_test, y_test, batch_size=32)\n",
        "\n",
        "# Load or build model\n",
        "initial_epoch = 0\n",
        "if os.path.exists(model_path):\n",
        "    print(\"✅ Loading model from last checkpoint...\")\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "else:\n",
        "    print(\"🚧 No previous model found. Building new model...\")\n",
        "    model = build_finetuned_resnet()\n",
        "\n",
        "# Check training log\n",
        "if os.path.exists(log_path) and os.path.getsize(log_path) > 0:\n",
        "    df = pd.read_csv(log_path)\n",
        "    initial_epoch = len(df)\n",
        "    print(f\"🔁 Resuming from epoch {initial_epoch}\")\n",
        "else:\n",
        "    print(\"📭 Log file is empty or not found. Starting from epoch 0.\")\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7),\n",
        "    ModelCheckpoint(best_model_path, save_best_only=True),\n",
        "    ModelCheckpoint(model_path, save_best_only=False),\n",
        "    CSVLogger(log_path, append=os.path.exists(log_path) and os.path.getsize(log_path) > 0)\n",
        "]\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=75,\n",
        "    initial_epoch=initial_epoch,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Output metrics\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(f\"Accuracy : {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall   : {recall:.4f}\")\n",
        "print(f\"F1-score : {f1:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=folders)\n",
        "disp.plot(cmap='Blues', values_format='d', ax=plt.gca())\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Save model and evaluation\n",
        "model.save(final_model_path)\n",
        "pd.DataFrame({\n",
        "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"],\n",
        "    \"Value\": [accuracy, precision, recall, f1]\n",
        "}).to_csv(os.path.join(output_dir, 'evaluation_metrics.csv'), index=False)\n",
        "\n",
        "print(\"✅ Training & evaluation selesai. Model dan hasil disimpan.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mdF2ct4V9w4o",
        "outputId": "7474e597-e0d1-4b98-e0ed-5cd5c3b5145c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loading model from last checkpoint...\n",
            "🔁 Resuming from epoch 3\n",
            "Epoch 4/75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 27s/step - accuracy: 0.8988 - loss: 0.2857 - val_accuracy: 0.8883 - val_loss: 0.3325 - learning_rate: 5.0000e-05\n",
            "Epoch 5/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m718s\u001b[0m 28s/step - accuracy: 0.8995 - loss: 0.2582 - val_accuracy: 0.9272 - val_loss: 0.2308 - learning_rate: 5.0000e-05\n",
            "Epoch 6/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m708s\u001b[0m 27s/step - accuracy: 0.9490 - loss: 0.1528 - val_accuracy: 0.9369 - val_loss: 0.1714 - learning_rate: 5.0000e-05\n",
            "Epoch 7/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m712s\u001b[0m 27s/step - accuracy: 0.9385 - loss: 0.1355 - val_accuracy: 0.9563 - val_loss: 0.1141 - learning_rate: 5.0000e-05\n",
            "Epoch 8/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 27s/step - accuracy: 0.9542 - loss: 0.1276 - val_accuracy: 0.9709 - val_loss: 0.0681 - learning_rate: 5.0000e-05\n",
            "Epoch 9/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m708s\u001b[0m 27s/step - accuracy: 0.9670 - loss: 0.0809 - val_accuracy: 0.9806 - val_loss: 0.0527 - learning_rate: 5.0000e-05\n",
            "Epoch 10/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m712s\u001b[0m 27s/step - accuracy: 0.9696 - loss: 0.0683 - val_accuracy: 0.9757 - val_loss: 0.0581 - learning_rate: 5.0000e-05\n",
            "Epoch 11/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 27s/step - accuracy: 0.9663 - loss: 0.0825 - val_accuracy: 0.9757 - val_loss: 0.0383 - learning_rate: 5.0000e-05\n",
            "Epoch 12/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m711s\u001b[0m 27s/step - accuracy: 0.9823 - loss: 0.0603 - val_accuracy: 0.9854 - val_loss: 0.0299 - learning_rate: 5.0000e-05\n",
            "Epoch 13/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 27s/step - accuracy: 0.9697 - loss: 0.0819 - val_accuracy: 0.9854 - val_loss: 0.0321 - learning_rate: 5.0000e-05\n",
            "Epoch 14/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m702s\u001b[0m 27s/step - accuracy: 0.9802 - loss: 0.0565 - val_accuracy: 0.9854 - val_loss: 0.0326 - learning_rate: 5.0000e-05\n",
            "Epoch 15/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 27s/step - accuracy: 0.9895 - loss: 0.0306 - val_accuracy: 0.9903 - val_loss: 0.0186 - learning_rate: 5.0000e-05\n",
            "Epoch 16/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m708s\u001b[0m 27s/step - accuracy: 0.9812 - loss: 0.0503 - val_accuracy: 0.9903 - val_loss: 0.0173 - learning_rate: 5.0000e-05\n",
            "Epoch 17/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 27s/step - accuracy: 0.9834 - loss: 0.0440 - val_accuracy: 0.9951 - val_loss: 0.0143 - learning_rate: 5.0000e-05\n",
            "Epoch 18/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m708s\u001b[0m 27s/step - accuracy: 0.9847 - loss: 0.0390 - val_accuracy: 0.9951 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
            "Epoch 19/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 27s/step - accuracy: 0.9870 - loss: 0.0324 - val_accuracy: 1.0000 - val_loss: 0.0062 - learning_rate: 5.0000e-05\n",
            "Epoch 20/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m708s\u001b[0m 27s/step - accuracy: 0.9852 - loss: 0.0382 - val_accuracy: 1.0000 - val_loss: 0.0049 - learning_rate: 5.0000e-05\n",
            "Epoch 21/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m705s\u001b[0m 27s/step - accuracy: 0.9822 - loss: 0.0511 - val_accuracy: 1.0000 - val_loss: 0.0071 - learning_rate: 5.0000e-05\n",
            "Epoch 22/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 27s/step - accuracy: 0.9923 - loss: 0.0332 - val_accuracy: 1.0000 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
            "Epoch 23/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m702s\u001b[0m 27s/step - accuracy: 0.9933 - loss: 0.0193 - val_accuracy: 0.9903 - val_loss: 0.0132 - learning_rate: 5.0000e-05\n",
            "Epoch 24/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m701s\u001b[0m 27s/step - accuracy: 0.9939 - loss: 0.0170 - val_accuracy: 1.0000 - val_loss: 0.0091 - learning_rate: 1.0000e-05\n",
            "Epoch 25/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m703s\u001b[0m 27s/step - accuracy: 0.9922 - loss: 0.0200 - val_accuracy: 1.0000 - val_loss: 0.0068 - learning_rate: 1.0000e-05\n",
            "Epoch 26/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m705s\u001b[0m 27s/step - accuracy: 0.9995 - loss: 0.0099 - val_accuracy: 1.0000 - val_loss: 0.0057 - learning_rate: 1.0000e-05\n",
            "Epoch 27/75\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 27s/step - accuracy: 0.9850 - loss: 0.0524 - val_accuracy: 1.0000 - val_loss: 0.0054 - learning_rate: 2.0000e-06\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5s/step\n",
            "Evaluation Metrics:\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1-score : 1.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training & evaluation selesai. Model dan hasil disimpan.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}